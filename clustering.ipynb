{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd484f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.datasets import get_rdataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ISLP import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import \\\n",
    "     (KMeans,\n",
    "      AgglomerativeClustering)\n",
    "from scipy.cluster.hierarchy import \\\n",
    "     (dendrogram,\n",
    "      cut_tree)\n",
    "from ISLP.cluster import compute_linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "Auto = load_data('Auto')\n",
    "Auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e75054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also impute the missing values of \"horsepower\" as we did previously\n",
    "\n",
    "Auto['horsepower'].replace('?','104',inplace=True)\n",
    "Auto['horsepower'] = pd.to_numeric(Auto['horsepower'])\n",
    "Auto.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094cabbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We won't use \"name\" in clustering--there are way too many levels to be useful. \n",
    "# Instead, we'll make the name of each car the index, so that we can use it in dendrograms.\n",
    "\n",
    "Auto.index = Auto['name']\n",
    "Auto.drop(columns='name', axis=1, inplace=True)\n",
    "Auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use just a sample of 10 vehicles to start\n",
    "# We'll use this to get a sense of what the clusters seem to look like\n",
    "\n",
    "import random\n",
    "random.seed(10) # ALWAYS set the seed! Otherwise we can't replicate our results\n",
    "\n",
    "# Create a random sample by randomly choosing row indices\n",
    "index = random.sample(range(Auto.shape[0]), 10)\n",
    "\n",
    "sample10 = Auto.iloc[index]\n",
    "sample10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b840507",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do an initial clustering exercise on the Auto data as is\n",
    "\n",
    "HClust = AgglomerativeClustering\n",
    "hc_comp = HClust(distance_threshold=0,\n",
    "                 n_clusters=None,\n",
    "                 linkage='complete')\n",
    "hc_comp.fit(sample10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7268961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create a dendrogram using matplotlib\n",
    "\n",
    "linkage_comp = compute_linkage(hc_comp)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "dendrogram(linkage_comp,\n",
    "           ax=ax,\n",
    "           leaf_rotation=90,\n",
    "           labels=sample10.index,\n",
    "           color_threshold=-np.inf,\n",
    "           above_threshold_color='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df535dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can even add colors based on the selected clusters\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "dendrogram(linkage_comp,\n",
    "           ax=ax,\n",
    "           leaf_rotation=90,\n",
    "           labels=sample10.index,\n",
    "           color_threshold=1000, # this is the important part \n",
    "           above_threshold_color='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc0be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can cut the tree (by number of clusters or by height) to get an array of cluster assignments\n",
    "\n",
    "cut_tree(linkage_comp, n_clusters=3).T\n",
    "#cut_tree(linkage_comp, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaacffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's attach the cluster assignments to our data\n",
    "# and sort by cluster number\n",
    "\n",
    "sample10['cluster']=cut_tree(linkage_comp, n_clusters=3)\n",
    "sample10.sort_values('cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e726328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmm, our clusters seem to be highly influenced by \"weight\"\n",
    "\n",
    "sample10.corr().style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42515af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the cluster assignment column so we can start over...\n",
    "\n",
    "sample10.drop(columns='cluster', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f6c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's standardize the data before clustering\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sample10_scale = scaler.fit_transform(sample10)\n",
    "sample10_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll run the algorithm again\n",
    "# Can we update this block to add colors for 3 clusters?\n",
    "\n",
    "hc_comp_scale = HClust(distance_threshold=0,\n",
    "                       n_clusters=None,\n",
    "                       linkage='complete').fit(sample10_scale)\n",
    "linkage_comp_scale = compute_linkage(hc_comp_scale)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "dendrogram(linkage_comp_scale, ax=ax, \n",
    "           leaf_rotation=90, labels=sample10.index,\n",
    "           color_threshold=-np.inf, above_threshold_color='black')\n",
    "ax.set_title(\"Hierarchical Clustering with Scaled Features\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00612d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the clusters from before and after standardizing\n",
    "\n",
    "sample10['cluster'] = cut_tree(linkage_comp, n_clusters=3)\n",
    "sample10['cluster_scale'] = cut_tree(linkage_comp_scale, n_clusters=3)\n",
    "sample10.sort_values('cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other types of linkage\n",
    "\n",
    "hc_sing_scale = HClust(distance_threshold=0,\n",
    "                       n_clusters=None,\n",
    "                       linkage='single').fit(sample10_scale)\n",
    "linkage_sing_scale = compute_linkage(hc_sing_scale)\n",
    "\n",
    "hc_avg_scale = HClust(distance_threshold=0,\n",
    "                      n_clusters=None,\n",
    "                      linkage='average').fit(sample10_scale)\n",
    "linkage_avg_scale = compute_linkage(hc_avg_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab06861",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1,ncols=3,figsize=(15, 5))\n",
    "\n",
    "dendrogram(linkage_comp_scale, ax=axes[0], \n",
    "           leaf_rotation=90, labels=sample10.index,\n",
    "           color_threshold=5, above_threshold_color='black')\n",
    "dendrogram(linkage_sing_scale, ax=axes[1], \n",
    "           leaf_rotation=90, labels=sample10.index,\n",
    "           color_threshold=2.6, above_threshold_color='black')\n",
    "dendrogram(linkage_avg_scale, ax=axes[2], \n",
    "           leaf_rotation=90, labels=sample10.index,\n",
    "           color_threshold=3.5, above_threshold_color='black')\n",
    "ax.set_title(\"Hierarchical Clustering with Scaled Features\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're done with the hierarchical cluster assignment columns, so we'll drop them before moving on\n",
    "\n",
    "sample10.drop(columns=['cluster','cluster_scale'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfea76d",
   "metadata": {},
   "source": [
    "## $K$-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a single K-means with K=3\n",
    "\n",
    "kmeans = KMeans(n_clusters=3,\n",
    "                random_state=1,\n",
    "                n_init=1).fit(sample10_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09be28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cluster assignments \n",
    "\n",
    "cluster_km = pd.DataFrame(kmeans.labels_)\n",
    "cluster_km.index=sample10.index\n",
    "cluster_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb1965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cluster assignments to the data\n",
    "\n",
    "sample10['cluster_km']=cluster_km\n",
    "sample10.sort_values('cluster_km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even though the data is 8-dimensional, we can plot pairs at a time\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "ax.scatter(sample10['mpg'], sample10['weight'], c=sample10['cluster_km'])\n",
    "ax.set_title(\"K-Means Clustering Results with K=3\")\n",
    "ax.set_xlabel('mpg')\n",
    "ax.set_ylabel('weight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ce7080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if we change the initial randomization?\n",
    "\n",
    "kmeans2 = KMeans(n_clusters=3,\n",
    "                random_state=2,\n",
    "                n_init=1).fit(sample10_scale)\n",
    "cluster_km2 = pd.DataFrame(kmeans2.labels_)\n",
    "cluster_km2.index=sample10.index\n",
    "cluster_km2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba7551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That wasn't helpful at all...let's append that column of cluster assignments to the existing data\n",
    "\n",
    "sample10['cluster_km2']=cluster_km2\n",
    "sample10.sort_values('cluster_km2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf45b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a plot of the new clusters produced with a different randomization. Totally different!\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "ax.scatter(sample10['mpg'], sample10['weight'], c=sample10['cluster_km2'])\n",
    "ax.set_title(\"K-Means Clustering Results with K=3\")\n",
    "ax.set_xlabel('mpg')\n",
    "ax.set_ylabel('weight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can automatically have the algorithm repeat itself many times and then take the optimal answer...\n",
    "# here we use 100 iterations.\n",
    "\n",
    "kmeans3 = KMeans(n_clusters=3,\n",
    "                random_state=1,\n",
    "                n_init=100).fit(sample10_scale)\n",
    "cluster_km3 = pd.DataFrame(kmeans3.labels_)\n",
    "cluster_km3.index=sample10.index\n",
    "cluster_km3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f54a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample10['cluster_km3']=cluster_km3\n",
    "sample10.sort_values('cluster_km3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the plot for the 'optimal'\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "ax.scatter(sample10['mpg'], sample10['weight'], c=sample10['cluster_km3'])\n",
    "ax.set_title(\"K-Means Clustering Results with K=3\")\n",
    "ax.set_xlabel('mpg')\n",
    "ax.set_ylabel('weight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd85e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can plot by different variables, too\n",
    "# can you find a pair of variables that show a meaningful difference between the clusters?\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "ax.scatter(sample10['year'], sample10['origin'], c=sample10['cluster_km3'])\n",
    "ax.set_title(\"K-Means Clustering Results with K=3\");\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('origin');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fdada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create a function to run k-means and make these plots automatically\n",
    "\n",
    "def kmeans_plot(data=sample10,n_clusters=3,var1='mpg',var2='weight'):\n",
    "    data_scale = scaler.fit_transform(data)\n",
    "    kmeans = KMeans(n_clusters=n_clusters,\n",
    "                    random_state=1,\n",
    "                    n_init=100).fit(data_scale)\n",
    "    cluster_km = pd.DataFrame(kmeans.labels_)\n",
    "    cluster_km.index=data.index\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "    ax.scatter(data[var1], data[var2], c=cluster_km)\n",
    "    ax.set_title(\"K-Means Clustering Results with K={}\".format(n_clusters))\n",
    "    ax.set_xlabel(var1)\n",
    "    ax.set_ylabel(var2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fbfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can you find a pair of variables that are important when you have 5 different clusters?\n",
    "\n",
    "kmeans_plot(data=Auto,\n",
    "            n_clusters=4,\n",
    "            var1='displacement',\n",
    "            var2='mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0eecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_plot(data=Auto,\n",
    "            n_clusters=5,\n",
    "            var1='horsepower',\n",
    "            var2='acceleration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da9505a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
